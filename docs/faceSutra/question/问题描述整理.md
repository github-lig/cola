- synchronized：jdk提供的可重入、非公平的同步阻塞原语，可以用来修饰方法和代码块。jvm会为每一个关联了synchronized的对象关联一个monitor监视器，当字节码执行器遇到monitorenter指令，或者调用方法时，方法的flags中包含ACC_SYNCHRONIZED，当前线程会先获取同步锁，然后在执行同步方法/代码块中的逻辑，如果获取失败，会在锁队列（entry_list）中等待。
	- 在jdk1.6，对synchronized进行了优化，提供了锁从偏向锁-轻量级锁-重量级锁的升级过程。
	- 首先线程A尝试获取锁，在mark word中设置当前线程id。当线程B获取锁时，如果线程A存活，并且占有着锁，将锁升级为轻量级锁，否则尝试cas设置mark word中的threadid指向自己，设置失败，也会将锁升级为轻量级锁。
	- B将锁升级为轻量级锁时，会等待安全点（没有字节码在执行），先暂停持有偏向锁的A线程，将锁升级为轻量级锁，标志位设置为00，并唤醒A线程，将mark word设置为指向栈中锁记录的指针，而mark word原本存有的hashCode和gc等信息会存放在栈中，此后B线程尝试自旋获取锁，如果获取超时或者在获取的过程中，有其它线程也在尝试获取锁，则会将锁升级为重量级锁，标志位设置为10。
	- 锁升级为重量级锁之后，获取锁失败的线程会并入ObjectMonitor监控器的entryList中阻塞，当持有锁的线程释放锁之后，entryList和waitset中被唤醒的线程都会竞争锁。
	- 锁粗化：将临近的同步代码块合并为一个，避免多次获取锁
	- 锁消除：JIT编译
	- 偏向锁用于几乎没有锁竞争的情况下，每次都是同一个线程获取锁。轻量级锁用于参与锁竞争的线程不多，并且同步逻辑执行快，其他线程可以通过自旋很快获取锁的情况下。
	- 自旋锁：因为线程的挂起和唤醒都需要转入内核态中完成，这些操作给系统的并发性能带来了很大的压力。自旋锁不能代替阻塞，虽然自旋等待本身虽然避免线程切换的开销，但是会占用处理器的时间。
	- 自适应自旋：自旋的时间不固定，如果在同一个锁对象上，自旋等待刚刚成功获取过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也很有可能再次成功，进而它将允许自旋等待时间持续相对更长的时间。如果在一个锁对象上很少成功获得过，那么这个对象很有可能会取消自旋过程。

- synchronized和lock的区别？
	- synchronized可以修饰方法和代码块，lock需要指定同步块的开始和结束
	- synchronized自动释放锁，lock需要手动释放
	- synchronized不能响应中断，而lock可以响应中断，并且可以尝试获取锁和超时获取锁。
	- synchronized只支持非公平锁，而lock支持公平和非公平两种模式。

- 悲观锁、乐观锁
	- 悲观锁，每次去拿数据的时候都认为别人会修改，所以每次拿数据都会上锁，这样别人拿数据的时候就会阻塞
		- java中的synchronized和ReentrantLock等独占锁
	- 乐观锁，每次拿数据都认为别人不会修改，所以不会上锁，但是在提交更新的时候会判断在此期间别人有没有更新数据。
		- CAS原子操作（AtomicXXX），每次修改的时候会比较一下值是否有变化。
			- 会出现ABA问题
			- 自旋CAS如果长时间不成功，会给CPU带来非常大的开销
		- 版本号。每次更新时，先读取版本号，再执行更新逻辑，如果版本号发生了变化，就重试更新操作。
	
- volatile：可见性和一定程度的有序性
	- 对一个volatile的读，总是能看到任意线程对这个变量最后的写入
	- 确保指令重排序时，保证当程序执行到volatile变量的读/写时，在其前面的操作已经全部运行，在其后面的操作都没有运行。
	- volatile变量在汇编语言中，相对于没有volatile的变量多了lock的前缀，也叫内存屏障。
	- 重排序是虚拟机为了优化执行速度进行的优化，但是会保证优化后的程序与优化前的程序在单线程的环境下执行的结果一致。


- hashmap：基于数组加链表实现，当链表长度达到阈值，会转换为红黑树，能够提高查找速度。
	- 如何解决hash冲突？拉链法，与hash表中冲突的元素组成链表。
	- hashmap如何扩容？首先，hashmap扩容的阈值是capacity * load factor。插入元素后判断，如果元素个数超过阈值，将触发扩容；或者将链表树化时，如果数组的长度小于64，也将扩容
		- 1.计算扩容后的容量，创建newtable，扩容一般是扩大二倍
		- 2.遍历之前的tab，通过hash & oldlength判断hash桶中的元素是在原来的index位置还是在index+oldlength的位置。
		- 3.关于TreeNode节点，扩容后如果hash桶中的元素个数小于6，则还原为链表。
- concurrenthashmap：基于hashmap，通过synchronized和cas保证线程安全性。
	- 如何扩容？和hashmap的条件一致
		- 1.计算每个线程处理的桶空间，默认为16
		- 2.将新表设置为oldtab的二倍
		- 3.计算当前线程此次要处理的下标范围
		- 4.如果桶内有数据，转移数据 （hash & oldlength计算要转移的位置）
	- GET？
		- 使用volatile修饰保证了可见性

- 如何用LinkedHashMap实现LRU？
	- 该集合维护了双向链表，可以记录插入顺序和访问顺序，每次访问某个元素的话，该元素会插入到链表的后方，当进行清理的时候，将链表首部的节点删除即可
- 如何用TreeMap实现一致性hash？
	-使用TreeMap存放虚拟节点，TreeMap<Long hash, Node 真实机器节点>，通过tailMap返回为空的话，返回map中的第一个虚拟节点。hash可以使用虚拟节点的名称计算，利用下述MurMurHash算法计算


- AOP：Spring的AOP依靠动态代理技术实现，为应用程序提供功能拓展、将固定模式的代码从业务中剥离出来单独维护。AOP为我们提供了在切入点的before/afterReturning/around/afterThrowable/after的增强。
	- AOP代理模式有两种，默认使用java动态代理（基于接口），cglib基于继承
	- AOP最常见的就是Spring事务模块提供的@Transactional注解为添加了该注解的方法提供事务的创建、提交、回滚的功能。
	- 常用的还有日志记录、性能监控等
- 动态代理和静态代理：对某个对象进行包装，以控制这个对象的访问（方法增强）。代理类需要和resource类有共同的父类接口。
	- 静态代理在编译的时候就确定了代理类。动态代理是在运行过程中生成代理类的。静态代理一般只能代理一个类，而动态代理可以代理多个实现了接口的类。

- jdk动态代理和cglib的区别：jdk动态代理只能代理实现了接口的类，通过反射机制生成实现该接口的类，通过调用被代理类的方法进行增强。而cglib是生成一个代理子类，覆盖其中的方法进行增强（因为采用了继承，所以该类和方法不要采用final修饰），底层使用asm进行字节码的生成。


- @Transactional
	- 如果方法B由@Transactional修饰，而A方法没有此注解，此时A去调用方法B，@Transactional失效




- 线程的状态及变化过程
	- 线程的状态有初始、运行、阻塞、等待、超时等待、终止六种状态，其中运行可以细分为就绪和运行中
	- 线程实例化之后状态为初始；调用start()方法状态为运行；获取同步锁失败/阻塞IO，进入阻塞状态；在阻塞状态被唤醒获取到锁/阻塞式IO完成，进入运行状态；运行中调用Thread.join()/Object.wait()/LockSupport.park()进入等待状态；在运行中调用Thread.sleep(long)/Object.wait(long)/Thread.join(long)/LockSupport.parkNanos()/LockSupport.parkUtil()进去超时等待状态；在等待/超时等待状态调用LockSupport.unpark()/Object.notify()/Object.notifyAll()进入运行状态；线程执行完成进去终止状态。
	
- JVM：类加载器、执行引擎、运行时区域、垃圾回收器、本地方法接口。
- 运行时区域包括：堆、虚拟机栈、本地方法栈、方法区（元空间）、程序计数器。
	- 程序中实例化的对象基本都是放到堆中
	- 虚拟机栈存储的是Java方法运行时数据
	- 方法区存储的是类元数据、静态变量、常量、编译后的代码
	- 程序计数器是线程私有，存储的是线程执行字节码的行号，用于线程恢复后能恢复正确执行的位置。

- finalize方法，最多执行一次
	- 在一个对象被标记为可回收对象时，如果对象覆写finalize()，并且没有执行过，那么会判定这个对象有必要执行finalize方法，加入到F-Queue的队列中，由低等级的finalizer线程执行，如果对象在finalize方法中重新与引用链上的任何一个对象建立关联的话，对象就完成了自救，它将被移除即将回收的集合。

- 垃圾回收算法
	- 标记-清理
	- 复制
	- 标记-整理


- Minor GC 和 Full GC？
- 

- STW
- 


- 垃圾回收器
- 

	
- AQS是一种提供了原子式状态管理、阻塞/唤醒线程以及队列模型的框架。


- tcp和udp：tcp数据传输协议，面向连接，基于字节流的传输层协议，支持失败重传和有序。udp用户数据报协议，无需建立连接，发送数据报，不可靠，不保证有序。


- 三次握手：1.客户端向服务端发送SYN+序号A，2.服务端收到SYN后回复SYN（序号B）+ACK(A+1)，3.客户端向服务端发送ACK（B+1），服务端收到该ack之后，连接正式建立
- 四次挥手：
	- A关闭向B的发送通道：
		- A发送FIN码（序号K），并且发送一个ACK，对B最后一次发送数据的确认
		- B返回ACK（序号K+1）
	- B关闭向A的发送通道：（收到A关闭的请求后，不一定关闭B向A发送的通道）
		- B发送FIN码（序号X）
		- A向B发送ACK（序号X+1）
- 原因：三次握手完之后，服务端和客户端都需要知道对方的发送和接收功能是完好的，第一次服务端知道客户端可以发送消息，第二次客户端知道服务端可以接收和发送消息，第三次，服务端知道客户端可以接收消息。  
 	   四次挥手，因为tcp连接是全双工的，客户端和服务端都可以发送和接收消息。

-  Spring Cloud 和 Dubbo：spring cloud是一套微服务的解决方案，由一系列组件提供功能支持。而dubbo是一个分布式的服务治理框架。
	-  两者最大的区别在于服务调用方面，dubbo采用的是RPC的方式调用，提供了多种基于长连接的NIO框架的封装，以及Hessian2等序列化方式，服务调用的性能较Spring Cloud的Http Rest方式高，但是dubbo服务提供方和调用方接口依赖方式太强，项目大的话，服务间的依赖管理会很麻烦，而Http Rest不会出现这种问题，只需要将接口维护到类似swagger上面就可以。
	-  cloud生态圈的组件完善，dubbo只是为我们提供了服务治理，如果需要使用配置中心等组件，需要整合，毕竟不是和dubbo无缝连接的组件，整合的话风险高一些。
	-  dubbo在国内用户人群广，文档多，而cloud文档相对较少，而且开发项目需要引入的组件较多，学习成本高。


- dubbo原理：
	- dubbo节点角色：提供者Provider、消费者Consumer、注册中心Registry、监控中心Monitor（非必须，监控服务的调用次数和调用时间）、服务运行容器Container
	- 服务容器负责启动，加载，运行服务提供者
	- 服务提供者在启动时，向注册中心注册自己提供的服务
	- 消费者在启动时，向注册中心订阅自己所需的服务
	- 注册中心返回消费者所需的服务列表，如果有更新，注册中心将基于长连接推送变更数据到消费者
	- 服务消费者从提供者列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，默认再选一台调用
	- 服务消费者和提供者在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心


- 容错模式（cluster）：失败重试、快速失败、失败记录、失败定时重试、forking（并行调用，只要有一个成功就算成功）、广播调用（一个失败就算失败）
- 负载：随机（默认）、轮询、最少活跃调用数、一致性哈希（带有相同参数的请求总是被发给同一个提供者）

- 分布式事务：根据场景不同，可分为SystemTransaction和BusinessTransaction。
	- 前者代表数据库事务，当某一张表数据量过大时，可能会垂直/水平拆分将数据分到两个不同的数据库实例中。比如常用的分库分表中间件sharding-jdbc，提供了基于X/A的实现，以及基于seata中AT模式的整合。
	- 后者代表

- kafka原理
	- 
	- 经验证，顺序写磁盘效率比随机写内存还要高，这是Kafka高吞吐率的一个很重要的保证
	- 上面一节还涉及到一个概念，即HW。HW俗称高水位，HighWatermark的缩写，取一个partition对应的ISR中最小的LEO作为HW，consumer最多只能消费到HW所在的位置。另外每个replica都有HW,leader和follower各自负责更新自己的HW的状态。对于leader新写入的消息，consumer不能立刻消费，leader会等待该消息被所有ISR中的replicas同步后更新HW，此时消息才能被consumer消费。这样就保证了如果leader所在的broker失效，该消息仍然可以从新选举的leader中获取。对于来自内部broker的读取请求，没有HW的限制。
	- 数据可靠性和持久性保证 request.required.acks min.insync.replicas
	- HW
	- ISR宕机顺序影响恢复



- 栈的原理和应用：左右括号是否正确匹配的经典问题
	- 遍历，遇到开括号压入栈中，遇到闭括号，如果栈中有元素，弹出，没有则失败，遍历到最后，如果栈中无元素，成功，否则失败




- 双亲委派机制：双亲委派是一个规范，它规定除了顶层的启动类加载器，其它每个加载器都应该有自己的父类加载器。当进行类加载时，首先把加载请求委派给父加载器完成，只有当父类加载器反馈无法完成加载时，自己才会尝试加载。


- 分布式锁的作用：1.提升效率，用锁来避免一个任务被不必要的执行两次。2.正确性，保证任务按照正确的步骤执行，防止两个节点同时操作一份数据，造成文件冲突、数据丢失。

- 分布式锁实现：
	- 基于redis的实现。通过set(key, value, px , mill, nx)获取锁，value为唯一值，用于解锁操作。ex代表不存在该key时才能设置，px设置缓存存活时间，单位为毫秒。解锁的时候需要比较当前key的value值是否与之前设置的值相等，为了保证原子性，需要使用lua脚本。
	- 如果需要考虑获取锁之后，主节点还没来得及将数据同步到从节点就挂掉的情况，可以采用官方给的Redlock算法。
		- 1.获取本地时间
		- 2.客户端使用相同的key和value依次在每个master上尝试获取锁（如果获取锁的时间超过锁操作的快速失效时间，则直接返回）
		- 3.计算获取锁的消耗是否小于锁超时时间，并且成功获取锁的节点是否超过master节点数的一半，如果满足则获取锁成功
		- 4.获取锁成功，客户端持有锁的时间为锁超时时间-获取锁的消耗时间
		- 5.如果获取失败，则尝试在所有master节点释放锁



- 缓存一致性：
	- 起因，为了提高查询速度，将数据库中的部分数据放到缓存中。为了保证数据库中数据和缓存中数据一致。
	- 应该先更新数据库，再更新缓存。但是可能会出现更新缓存失败的情况，可以通过使用阿里的canal将mysql数据库的binglog进行收集，异步处理缓存数据。简单的可以设置失效时间，但是设置失效时间的话，要注意缓存雪崩的问题，失效时间不要都设置成一样的，可以在某个范围内随机。
	- 先更新缓存，后更新数据库存在的问题：A更新数据，B查询，如果A删除缓存之后，B查询cache miss，然后查询数据库更新缓存，此后A才更新数据库；A更新数据，B更新数据，因为更新数据库和更新缓存不是一个原子性操作，会出现A update redis -> B update redis -> B update db -> A update db

- redis淘汰策略：
	- 1.设置带过期时间的key时，为这个key创建一个定时器
	- 2.当访问的时候，判断key是否失效
	- 3.后台周期性的选择100个设置了失效时间的key进行失效删除，当有1/4的key失效，就再选取100个


- redis一致性hash：
	- 
	- redis集群模式，为了降低redis节点失效对key造成的影响，


- redis持久化：AOF和RDB
	- AOF追加文件，实时性高，可以选择每次有数据修改时就写入文件，或者每秒钟写入异常，或者让操作系统决定。
	- RDB快照存储，默认存储方式，在conf中可以配置指定时间内key的变化量来执行持久化命令BGSAVE（fork出一个子线程将数据保存到磁盘）
	- 在redis4.0开始，支持RDB和AOF的混合持久化（默认关闭）
	- AOF重写，生成一个新的AOF文件，读取现有的键值对，写入AOF文件中，redis维护了一个AOF缓存区，用来记录AOF文件生成的过程中服务器执行的所有写命令。AOF生成后，将缓存区中的内容加到AOF文件末尾，然后使用该文件替换老的AOF文件。
	- 如果开启了混合持久化，AOF文件重写时，会直接把RDB文件的内容写入新的AOF文件头，但是不再是AOF格式，可读性差些。

- redis事务
	- 通过MULTI、EXEC、WATCH等命令实现，将多个命令打包发给服务端，事务执行期间，redis不会停止事务去执行其他命令。但是如果事务中某条命令执行失败，也不会回滚，会继续执行下去
	- UNWATCH、DISCARD

- redis zset跳表
	- 维护多条链路

- redis pipeline管道？
	- 将多条命令缓存在客户端，一次性发送到服务端执行。。而事务Multi是将命令发送到服务端，在服务端缓存，最后一次性执行。






- lru最近最久未使用。lfu最近最少使用  lru是基于访问时间，而lfu是基于访问次数
- 

- 数据库设计：找主表-表关系（一对多）-垂直拆分-索引后加
	- 


- 索引：Innodb 聚族索引，B+ 树，数据放在主索引的叶子节点上，辅助索引叶子节点指向的是主键索引，这也是innodb需要主键的原因。Myisam非聚族索引（索引文件和数据文件时分离的），B+树，索引树叶子节点存储的是data域数据记录的地址，所以可以不要主键
	- 索引是对表中的一列或者多列进行排序的一种存储结构，索引是表的一部分
	- 索引的作用：优化查询性能，对索引列进行排序，避免全表扫描
	- 索引类型：单列索引、组合索引。可以设置为全文索引、普通索引（可以指定以某个字段的前缀为索引）、唯一索引。特殊的是主键索引
	- 索引的设计原则
		- 索引列不能参与计算，比如时间类型转换
		- 尽量拓展索引，而不是新建，拓展的时候需要注意最左前缀原则
		- 如果某个表查询很少，更新/插入/删除很多，不建议建立索引，插入/删除/更新会更新索引
		- innodb下主键不宜过长，因为辅助索引date域存储的是主键的值，主键过长会导致辅助索引过大
		- 索引列的离散性要高
- sql查询很慢：
	- 偶尔很慢
		- 数据库在刷新脏页，例如redo log写满了需要同步磁盘
		- 执行时遇到了锁，表级锁/行级锁
	- 一直很慢
		- 索引没建立
		- 索引列参与了运算
		- 使用时没满足索引列的最左前缀原则

- mvcc：
	- 每一列都有创建版本号和删除版本号。存储的是事务的版本号。
	- select时，创建版本号<=当前事务版本号 && （删除版本号为空 || 删除版本号 > 当前事务版本号）
	- delete时，保存删除版本号为当前事务版本号
	- update时，插入一条新数据，创建版本号为当前事务版本号，保存删除行的删除版本号为当前事务版本号
	- insert时，保存创建版本号为当前事务版本号

	- 快照读：select * from xxx where xxx;
	- 当前读：select * from xxx where xxx for update/lock in share mode;
	- 事务隔离级别定义的是当前读的级别
	- RR级别下，当更新一条数据时，会对这条数据的前后区间加入gap锁，这样事务就无法在这两个区间插入数据
	- 行锁防止别的事务修改/删除,GAP锁防止了插入。两者组合到一起形成的Next-key，解决了RR级别的幻读问题。

- binlog redolog undolog
	- binlog 记录sql语句
	- redolog 用于事务提交
	- undolog 用于事务回滚

- myisam和innodb的区别？如何选择（读写分离的读库一般用myisam）？
	- myisam不支持事务，不支持行级锁。innodb支持事务和行级锁
	- myisam索引类型为非聚族索引，数据单独存放，而innodb是聚族索引，数据存储在主键索引树的叶子节点
	- innodb支持外键

- 为什么会选择B+树作为索引类型？
	- B+树的高度比其他树低
	- B+树叶子节点存储数据，并且还有指向下个叶子结点的指针

- 查询在什么时候不走预期中的索引？
	- 索引大量重复
	- 用了or，而且不是or中的所有字段都建了索引
	- like模糊查询以%开头
	- 列类型是字符串，但是没用''包裹（隐式转换）
	- 不满足最左前缀原则
	- 使用了<> 或 !=
	- 索引列is null, is not null
	- 索引列参与了运算


- sql常见优化？limit优化、索引、select *不会走覆盖索引
	- 分页查询时，先查出来id
	- 尽量不要select * 。必定不会覆盖索引（select的列只用从索引中就能够取得，不用查询数据行）


- 事务隔离级别：
	- 读未提交：脏读、不可重复读、幻读
	- 不可重复读：不可重复读、幻读
	- 可重复读（RR）：幻读
	- 串行化

- spring事务传播行为：
	- REQUIRED（默认）：如果当前没有事务，则新建一个，如果有，加入当前事务
	- SUPPORT：支持当前的事务，如果没有，就以非事务方式运行
	- MANDATORY：支持当前事务，如果没有，抛出异常
	- NEW：创建一个事务，如果当前有事务，挂起
	- NOT_SUPPORT：不支持事务，如果当前有事务，挂起
	- NEVER：不支持事务，如果当前有事务，抛出异常
	- NESTED：嵌套事务，如果当前存在事务，则在嵌套事务中执行，没有则新建一个事务

- spring嵌套事务：嵌套事务失败不会影响父事务，父事务的成功与否会影响嵌套事务

- @Transactional不生效的原因
	- 方法是不是public
	- 是否在回滚异常的范围内
	- 异常是否被捕获
	- 在类内部调用，这样就不会走代理了


- 系统设计：大-服务边界
	- 必要性
	- 拆分的边界，松耦合、复用性

- zookeeper：
	- 分布式系统（分布式协调服务，可以在分布式系统中共享配置，集群管理，协调锁资源，提供命名服务），半数以上节点存活，就可以提供服务
	- 集群节点类型：leader、follower、observer。leader只有一个，用来处理写请求和读请求；follower参与选举leader，可以处理读请求，写请求会被转发到leader处理；observer不参与选举，处理读请求，可以通过增加observer来提交zk集群的读性能。
	- 数据节点类型：（有序）持久节点、（有序）临时节点
	- 类文件系统的存储结构，在树节点存储数据，数据存储在内存中，但是会持久化，单个节点不超过1M
	- 客户端与zk建立的是长连接，watcher机制，实现对节点更新/删除/增加子节点等的监听
	- 顺序一致性，从同一个客户端发送的请求，最终会严格的按照顺序执行

- zookeeper如何保证主从节点一致性的？zab协议。不能保证强一致性，保证最终一致性
	- zookeeper atomic broadcast，包括恢复模式（选主）和广播模式（同步），解决了zk集群崩溃恢复和主从同步数据的问题。
	- 主从数据同步，类似于2PC，用来保证集群中半数以上机器能够和leader服务器的数据状态保存一致
		- leader在处理写请求时，先广播proposal给follower
		- follower收到proposal提议之后，先将事务日志写入磁盘，然后返回ack给leader
		- leader收到半数以上ack消息，广播commit消息给follower，同时自身也会完成事务的提交，并向客户端返回成功
	- 恢复模式（选主）发生在集群启动和运行中leader死机或者与一半以上从机失去联系
		- zk节点的状态：looking选举状态、leading leader的状态、following follower的状态
		- 每次写成功的消息，都会有一个全局唯一的标识，zxid。64位，前32位代表选举纪元，后32位递增
		- 1.选投票给自己
		- 2.收到投票后，如果发现zxid比自己的大，更新投票，如果zxid一样，比较服务器节点id
		- 3.如果判断有半数以上机器投票给某个节点，那么这个节点就是leader

- 基于zookeeper如何实现分布式锁？
	- 基于临时有序节点实现
	- 1.在锁节点下创建临时有序节点
	- 2.创建成功后，获取锁节点下所有的子节点，判断自己创建的是不是序号最小的节点
	- 3.如果是，获取锁成功
	- 4.如果不是，监听比自己小的第一个节点，当监听的节点失效时，获取锁成功
	- 5.执行完之后删除节点



- Junit注解：beforeclass(首先执行，只执行一次)，afterclass（最后执行，只执行一次），before（每一个测试用例执行前执行），after（每一个测试用例执行后执行）


- ThreadLocal：线程本地变量，多个线程访问同一个threadlocal变量时，读取的值是不一样的。
	- 每个Thread中有一个ThreadLocalMap属性，以ThreadLocal为key（软引用），设置的值为value存储在线程中。
	- 适用场景：线程共享变量；变量在方法之间共享，但不希望被多线程共享

- 引用类型：强软弱虚
	- 为对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收的时收到一个系统通知


- 分布式事务
	- 

- spring注解如何生效、类是如何扫描的：https://www.cnblogs.com/xrq730/p/6285358.html


- 分布式系统：将系统垂直切分为多个模块，各个模块之间通过网络连接，协作完成一个特定任务的系统。
	- 分布式最重要的两点：服务拆分、节点通信
	- 分布式和集群的区别：分布式是多个不同的节点协作完成一件事情，集群是相同的节点提供某种服务
	- 微服务相对于分布式系统来说，粒度更小，服务间的耦合度更低。
	- 分布式定理：CAP
		- C 一致性，数据在多个副本之间保持一致。
		- A 可用性，每次请求都能在有限时间内（不同的系统会不一样）获得正常响应，无论对错
		- P 分区容错性，因为分布式系统依靠网络进行协作，当网络出现分区时，系统仍然能够提供一致性和可用性的服务
		- 因为网络的不可靠性，所以P是必须满足的，需要在C和A中间满足一个。
	- CAP定理的妥协，base
		- 基本可用：在分布式系统出现不可预知故障时，允许损失部分可用性。比如响应时间的延长，部分功能熔断降级。典型的例如如淘宝双11时，部分用户会出现系统无法访问的页面
		- 软状态：允许数据副本在同步时存在延迟，并认为该中间状态不会影响系统的整体可用性
		- 最终一致：数据副本在经过一段时间后，最终会达到一直的状态。典型的如关系型数据库的主备数据复制
		- base其实就是牺牲数据的一致性来满足系统的高可用性，系统中的一部分数据不可用或者不一致，仍需要保持系统整体“主要可用”


 

- 注解：
-



- Class.forName和ClassLoader.loadClass的区别
	- Class.forName会执行静态变量的初始化，加载类还是使用的loadClass

- 反射创建实例
	- Class.newInstance()调用无参构造
	- Constructor.newInstance()可以是无参和有参的构造函数


- 监控：
	- 接口、sql、某段代码执行的次数以及运行时间-Transaction
	- 某些异常、重要逻辑执行的次数
	- 某些业务指标。比如订单数、交易额、订单成功率
	- 系统状态。jvm、gc、cpu

- 保障服务稳定的三大利器：熔断降级、服务限流、故障模拟
	- 熔断降级针对以下三个方面为依据rt（单位时间平均响应时长）、异常数、异常比例
	- 服务限流可以限制QPS和并发线程数

- 限流算法：计数器算法、令牌桶、漏桶
	- 计数器算法，比如设置了1s内的qps为10。从第一个请求进来开始，在接下来的1s内，没来一个请求，就把计数器+1，当计数器达到10时，拒绝后续的请求，直到1s时间结束，将计数器置为0。
		- 弊端1：如果事务处理快，在前10ms已经处理完。那么后面的990ms内的资源就浪费了。
		- 弊端2：如果每个事务处理时长大于1s，那么就会出现后续每s内处理的请求大于设置的qps，造成服务器的压力增大
	- 漏桶，类似于漏斗，比如每10ms处理一个请求。可以使用ScheduledThreadPoolExecutor延迟线程池实现（delayQueue）
		- 无法应对短时间的突发流量
	- 令牌桶，和漏斗模式不同，令牌桶是定期生成令牌，放入可以存放固定令牌的桶中，当请求来到的时候，先去令牌桶中取得令牌，之后才可以处理。可以使用google的guava包中的rateLimiter。



- mybatis $ #：#Mybatis会创建ParparedStatment参数占位符，通过占位符安全的设置参数。而使用$的话，不会进行转义
	- mybatis在对sql预编译之前会对sql进行解析。#{}会被替换为jdbc中preparedstatment的占位符，${}仅仅是字符串替换，在解析阶段将会进行变量替换。


- sql执行流程
-


- 吞吐量：三大因素QPS、平均响应时长（rt）、并发数
	- QPS=总量/时间 （事务/s）
	- 并发数=QPS*rt


- 多态是同一个行为具有多个不同表现形式或形态的能力


- 服务划分
	- 高内聚、每个服务需要有单独的数据库，避免在进行某些业务逻辑时，频繁的调用其他的服务
	- 要么保证业务的完整性、要么保证服务的通用性。不能只为了微服务的微而拆分
	- 从业务角度出发，不仅要保证业务需要，也要保持服务能力的通用性和拓展性
	- 某个信息的可信来源只能有一个，比如订单中心负责维护订单，不能在支付中心同样维护了一份订单，系统之间通过订单号进行关联
	- 中台或者说soa，最终都是为了提高服务的可靠性和高性能，并且能给业务的响应和创新带来高效助推能力
	- 服务是为了业务服务的，所以不能做太过超前的设计，也不能做理想化的设计，认为业务是一成不变的
	- 服务拆分会带来分布式事务和问题排查的难题


- 服务划分总结：服务划分可以从两个领域来入手，1是业务，2是技术


业务沉淀出服务中心，服务中心孕育创新（基于数据完整性等），助力业务发展

- 商品中心：商品描述能力、商品发布能力、商品管理能力、商品巡检能力、商品数据数据分析能力、商品评价能力



- rpc和mq的选择 https://my.oschina.net/u/3421984/blog/1800633
	- 不需要返回值、不希望发送端受限于消费端的处理速度
	- 处理的时效性不会影响当前流程的进行
	- 业务流过长的话，可以将允许同步执行的处理通过mq并发执行


- instanceof和isAssignableForm
	- obj instanceof 类名  判断obj是否是类名或者其子类的实例
	- ClassA.isAssignableForm(ClassB) ClassA和ClassB是Class对象，判断A和B是否相同，或者A是B的超类或接口


- 破坏单例的方式
	- 反射调用构造器
		- 可以通过在构造器中加入判断来避免
	- 序列化和反序列化
		- 可以通过增加readResolve方法来避免，反序列化执行过程中，会调用ObjectInputStream#readOrdinaryObject方法，这个方法会判断对象类是否包含readResolve方法，如果包含，直接返回该方法返回的对象


- 写磁盘方式
	- 同步刷盘：在返回写成功状态时，消息可能只是被写入内存的pagecache，写操作返回快，吞吐量大。当内存里的消息量达到一定程度时，统一触发写磁盘操作，快速写入。
	- 异步刷盘：在返回写成功状态时，消息已经被写入磁盘。具体流程时，消息写入内存的pagecache后，立即通知刷盘线程刷盘，然后等待刷盘完成，刷盘线程执行完成后唤醒等待的线程，返回消息写入成功的状态。

- 主从复制方式-消息从leader复制到follower
	- 同步复制：leader和follower均写入成功才返回写入成功的状态
	- 异步复制：leader写入成功就返回写入成功的状态

- rocketmq和kafka的区别
	- 可靠性：rocketmq支持同步/异步刷盘，同步/异步复制，kafka只支持异步刷盘。一般通过异步刷盘，同步复制的方式来保证可靠性
	- rocketmq支持事务消息
	- 消息回溯：kafka支持offset级别的回查，rocketmq支持按照时间回查，精度为毫秒，
	- 消息查询：kafka不支持消息查询，rocketmq支持根据MessageId查询，也支持根据消息内容查询
	- 定时消息：rocketmq支持定时消息
	- 失败重试：rocketmq支持失败重试（集群模型消息，广播消息不支持），每次重试时间间隔顺延，如果重复失败持续到一定次数（默认为16次），就会投递到死信队列。
	- 分区/队列支持：rocketmq单机支持的队列数更多，单机最多支持5w个队列，性能稳定。而kafka单机超过64个分区的话，消息发送性能降低严重


- rocketmq和kafka的可靠性保证
	- consumer端
		- rocketmq：通过pushConsumer消费时，业务实现消费回调的时候，当且仅当此回调函数返回ConsumeConcurrentlyStatus.CONSUME_SUCCESS时，mq才会认为这条消息处理成功。如果消息消费失败，返回ConsumeConcurrentlyStatus.RECONSUME_LATER或者消费时抛出异常，也会返回ConsumeConcurrentlyStatus.RECONSUME_LATER，为了保证消费至少被成功消费一次，mq会将返回了RECONSUME_LATER的消息投递到GROUP_ID对应的retry topic。在延迟了某个时间（默认10s）后再将这个消息投递到这个消费组。当重试次数达到16次，会投递到死信队列。
			- rocketmq的偏移量问题：mq通过offset来描述消费组在这条queue上的消费进度，每次消息消费成功后，本地的消费进度会被更新，然后由定时器定时同步到broker，来持久化消费进度。但是每次记录消费进度的时候，只会把一批消息中的最小的offset值作为消费进度值。如果一个批次中有某个offset的消息一直没被消费完，有可能出现消息重复消费的情况
		- kafka：单线程消费时可以保证至少消费一次。consumer端开启多线程异步消费时，需要关闭自动提交偏移量，consumer程序自身来处理offset的提交更新。
		- 需要注意的一点，consumer端也会维护自己消费的offset，所以不会出现，消息消费失败，不提交偏移量还能重新拉取该消息。offset是用来保证rebalance等情况下，queue被不同consumer消费时，会从已经提交的offset出开始拉取消息



- 为什么需要多任务处理？
	- 不仅仅是因为计算机的处理能力强大了，还有一个很重要的原因是计算机的运算速度与它的存储和通信子系统的速度差距太大，大量的时间花费在磁盘I/O、网络通信、数据库访问上。为了避免处理器大部分时间都处于等待其他资源的空闲状态，使用多任务处理可以把处理器的运算能力压榨出来。
	- 除了充分利用计算机处理器的能力外，一个服务端要同时对多个客户端服务，则是另一个更具体的并发场景
		- 对于计算量相同的任务，程序线程协调的越有条不紊，效率自然就会越高。反之，线程之间频繁争用数据，互相阻塞甚至死锁，将会大大降低程序的并发能力